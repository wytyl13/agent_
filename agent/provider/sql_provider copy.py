#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time    : 2024/12/24 11:35
@Author  : weiyutao
@File    : sql_provider.py
"""
import traceback
from sqlalchemy import select
from pydantic import BaseModel, model_validator, ValidationError
from typing import (
    AsyncGenerator,
    AsyncIterator,
    Dict,
    Iterator,
    Optional,
    Tuple,
    Union,
    overload,
    Generic,
    TypeVar,
    Any,
    Type,
    List
)
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker, DeclarativeBase
from sqlalchemy.ext.declarative import declarative_base
import numpy as np
from contextlib import contextmanager
import traceback
import urllib.parse
from sqlalchemy import and_
from datetime import datetime, date
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from contextlib import asynccontextmanager
import asyncio

from agent.provider.base_provider import BaseProvider
from agent.config.sql_config import SqlConfig

# å®šä¹‰åŸºç±»
class Base(DeclarativeBase):
    pass

# å®šä¹‰æ³›å‹ç±»å‹å˜é‡
ModelType = TypeVar("ModelType", bound=Base)


class SqlProvider(BaseProvider, Generic[ModelType]):
    sql_config_path: Optional[str] = None
    sql_config: Optional[SqlConfig] = None
    sql_connection: Optional[sessionmaker] = None
    model: Type[ModelType] = None
    database_type: str = "mysql"
    
    def __init__(
        self, 
        model: Type[ModelType] = None,
        sql_config_path: Optional[str] = None, 
        sql_config: Optional[SqlConfig] = None
    ) -> None:
        super().__init__()
        self._init_param(sql_config_path, sql_config, model)
    
    
    def _init_param(self, sql_config_path: Optional[str] = None, sql_config: Optional[SqlConfig] = None, model : Type[ModelType] = None):
        self.sql_config_path = sql_config_path
        self.sql_config = sql_config
        self.sql_config = SqlConfig.from_file(self.sql_config_path) if self.sql_config is None and self.sql_config_path is not None else self.sql_config
        
        # è®¾ç½®æ•°æ®åº“ç±»å‹
        if self.sql_config and hasattr(self.sql_config, 'database_type'):
            self.database_type = self.sql_config.database_type.lower()
        else:
            self.database_type = "mysql"  # é»˜è®¤å€¼ï¼Œä¿è¯å‘åå…¼å®¹
        
        # æ ‡å‡†åŒ–postgresqlç±»å‹åç§°
        if self.database_type == "postgres":
            self.database_type = "postgresql"
        
        
        # éªŒè¯æ•°æ®åº“ç±»å‹
        if self.database_type not in ["mysql", "postgresql", "postgres"]:
            raise ValueError(f"Unsupported database type: {self.database_type}. Supported types: mysql, postgresql")
        
        # if self.sql_config is None and self.data is None:
        #     raise ValueError("config config_path and data must not be null!")
        self.sql_connection = self.get_sql_connection() if self.sql_connection is None else self.sql_connection
        self.model = model
        if self.model is None:
            raise ValueError("model must not be null!")

    
    def get_sql_connection(self):
        try:
            sql_info = self.sql_config
            username = sql_info.username
            database = sql_info.database
            password = sql_info.password
            host = sql_info.host
            port = sql_info.port
        except Exception as e:
            raise ValueError(f"fail to init the sql connect information!\n{self.sql_config}") from e
        # å› ä¸ºurlä¸­çš„å¯†ç å¯èƒ½å­˜åœ¨å†²çªçš„å­—ç¬¦ä¸²ï¼Œå› æ­¤éœ€è¦åœ¨è¿›è¡Œæ•°æ®åº“è¿æ¥å‰å¯¹å…¶è¿›è¡Œç¼–ç 
        # urllib.parse.quote_plus() å‡½æ•°å°†ç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºå…¶ URL ç¼–ç çš„å¯¹åº”é¡¹ã€‚ä¾‹å¦‚ï¼Œ! å˜ä¸º %21ï¼Œ@ å˜ä¸º %40ã€‚è¿™ç¡®ä¿äº†å¯†ç è¢«è§†ä¸ºå•ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶ä¸”ä¸ä¼šç ´å URL è¯­æ³•ã€‚
        encoded_password = urllib.parse.quote_plus(password)
        # æ ¹æ®æ•°æ®åº“ç±»å‹æ„å»ºä¸åŒçš„è¿æ¥å­—ç¬¦ä¸²
        if self.database_type == "mysql":
                # MySQL å¼‚æ­¥é©±åŠ¨
            database_url = f"mysql+aiomysql://{username}:{encoded_password}@{host}:{port}/{database}"
            # æˆ–è€…ä½¿ç”¨ asyncmyï¼š
            # database_url = f"mysql+asyncmy://{username}:{encoded_password}@{host}:{port}/{database}"
        elif self.database_type == "postgresql":
            database_url = f"postgresql+asyncpg://{username}:{encoded_password}@{host}:{port}/{database}"
        
        try:
            # ä¸¤ç§æ•°æ®åº“éƒ½ä½¿ç”¨å¼‚æ­¥å¼•æ“
            engine = create_async_engine(
                database_url, 
                pool_size=10, 
                max_overflow=20,
                pool_pre_ping=True
            )
            SessionLocal = async_sessionmaker(bind=engine)
            return SessionLocal
        except Exception as e:
            raise ValueError("fail to create the sql connector engine!") from e
    
    
    def set_model(self, model: Type[ModelType] = None):
        """reset model"""
        if model is None:
            raise ValueError('model must not be null!')
        self.model = model
    
    
    @asynccontextmanager
    async def get_db_session(self):
        """æä¾›æ•°æ®åº“ä¼šè¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if not self.sql_connection:
            raise ValueError("Database connection not initialized")
        
        # ç»Ÿä¸€å¼‚æ­¥å¤„ç†ï¼Œä¸åŒºåˆ†æ•°æ®åº“ç±»å‹
        async with self.sql_connection() as session:
            try:
                yield session
                await session.commit()
            except Exception as e:
                await session.rollback()
                raise e
    
    
    async def add_record(self, data: Dict[str, Any]) -> int:
        """æ·»åŠ è®°å½•"""
        async with self.get_db_session() as session:
            try:
                record = self.model(**data)
                session.add(record)
                session.flush()  # åˆ·æ–°ä»¥è·å–ID
                record_id = record.id
                return record_id
            except Exception as e:
                error_info = f"Failed to add record: {e}"
                self.logger.error(error_info)
                self.logger.error(traceback.print_exc())
                raise ValueError(error_info) from e
    
    
    async def bulk_insert_with_update(self, data_list: List[Dict[str, Any]]) -> int:
        """æ‰¹é‡æ’å…¥ï¼Œé‡åˆ°é‡å¤æ•°æ®æ—¶è¦†ç›–æ—§æ•°æ®"""
        if not data_list:
            return 0
        
        try:
            from sqlalchemy import text
            
            table_name = self.model.__tablename__
            sample_data = data_list[0]
            columns = [col for col in sample_data.keys() if col != 'id']
            columns_str = ', '.join(columns)
            
            success_count = 0
            
            async with self.get_db_session() as session:
                for data in data_list:
                    try:
                        clean_data = {k: v for k, v in data.items() if k != 'id'}
                        
                        # æ„å»ºå•æ¡æ’å…¥SQLï¼ˆä½¿ç”¨æ–°è¯­æ³•ï¼‰
                        placeholders = ', '.join([f':{col}' for col in columns])
                        updates = ', '.join([f'{col} = VALUES({col})' for col in columns])
                        
                        # å…¼å®¹ä¸åŒMySQLç‰ˆæœ¬çš„å†™æ³•
                        if self.database_type == "mysql":
                            # MySQL è¯­æ³•
                            sql = f"""
                            INSERT INTO {table_name} ({columns_str})
                            VALUES ({placeholders})
                            ON DUPLICATE KEY UPDATE {updates}
                            """
                        elif self.database_type == "postgresql":
                            # PostgreSQL è¯­æ³• (éœ€è¦æŒ‡å®šå†²çªå­—æ®µï¼Œå‡è®¾æ˜¯ä¸»é”® id)
                            updates_pg = ', '.join([f'{col} = EXCLUDED.{col}' for col in columns])
                            sql = f"""
                            INSERT INTO {table_name} ({columns_str})
                            VALUES ({placeholders})
                            ON CONFLICT (id) DO UPDATE SET {updates_pg}
                            """
                        
                        session.execute(text(sql), clean_data)
                        success_count += 1
                        
                    except Exception as e:
                        self.logger.error(f"æ’å…¥å¤±è´¥: {e}, æ•°æ®: {clean_data}")
                        continue
                
                session.commit()
            
            self.logger.info(f"æ‰¹é‡æ’å…¥/æ›´æ–°å®Œæˆ: {success_count}/{len(data_list)} æ¡æˆåŠŸ")
            return success_count
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡æ’å…¥/æ›´æ–°å¤±è´¥: {e}")
            return 0
    
    
    
    async def bulk_insert_with_update_bake(self, data_list: List[Dict[str, Any]]) -> int:
        """æ‰¹é‡æ’å…¥ï¼Œé‡åˆ°é‡å¤æ•°æ®æ—¶è¦†ç›–æ—§æ•°æ®"""
        if not data_list:
            return 0
        
        try:
            from sqlalchemy import text
            
            # è·å–è¡¨å
            table_name = self.model.__tablename__
            
            # æ„å»ºå­—æ®µåˆ—è¡¨ï¼ˆæ’é™¤è‡ªå¢ä¸»é”®idï¼‰
            sample_data = data_list[0]
            columns = [col for col in sample_data.keys() if col != 'id']
            columns_str = ', '.join(columns)
            
            # æ„å»ºVALUESå ä½ç¬¦
            values_placeholder = ', '.join([f':{col}' for col in columns])
            
            # æ„å»ºUPDATEéƒ¨åˆ†ï¼ˆè¦†ç›–æ‰€æœ‰å­—æ®µï¼‰
            update_assignments = []
            for col in columns:
                update_assignments.append(f'{col} = VALUES({col})')
            update_str = ', '.join(update_assignments)
            
            # æ„å»ºå®Œæ•´SQL
            sql = f"""
            INSERT INTO {table_name} ({columns_str})
            VALUES ({values_placeholder})
            ON DUPLICATE KEY UPDATE {update_str}
            """
            
            success_count = 0
            async with self.get_db_session() as session:
                for data in data_list:
                    try:
                        # ç§»é™¤idå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        clean_data = {k: v for k, v in data.items() if k != 'id'}
                        session.execute(text(sql), clean_data)
                        success_count += 1
                    except Exception as e:
                        self.logger.error(f"æ’å…¥å¤±è´¥: {e}")
                        continue
                
                session.commit()
            
            self.logger.info(f"æ‰¹é‡æ’å…¥/æ›´æ–°å®Œæˆ: {success_count}/{len(data_list)} æ¡æˆåŠŸ")
            return success_count
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡æ’å…¥/æ›´æ–°å¤±è´¥: {e}")
            return 0
    
    
    async def delete_record(self, record_id: int, hard_delete: bool = False) -> bool:
        """è½¯åˆ é™¤è®°å½•"""
        async with self.get_db_session() as session:
            try:
                stmt = select(self.model).where(
                    self.model.id == record_id,
                    self.model.deleted == False
                )
                result = await session.execute(stmt)
                record = result.scalar_one_or_none()
                return {key: value for key, value in record.__dict__.items() 
                        if key != '_sa_instance_state'} if record else None
            except Exception as e:
                error_info = f"Failed to get record by id: {record_id}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e
    
    
    def update_record(self, record_id: int, data: Dict[str, Any]) -> bool:
        """æ›´æ–°è®°å½•"""
        with self.get_db_session() as session:
            try:
                result = session.query(self.model).filter(
                    self.model.id == record_id,
                    self.model.deleted == False
                ).update(data)
                return result > 0
            except Exception as e:
                error_info = f"Failed to update record {record_id} with data: {data}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e


    async def update_record_enhanced(self, record_id: int, data: Dict[str, Any], return_updated: bool = True) -> Optional[Dict[str, Any]]:
        """
        å¢å¼ºç‰ˆæ›´æ–°è®°å½•å‡½æ•°
        
        Args:
            record_id (int): è¦æ›´æ–°çš„è®°å½•ID
            data (Dict[str, Any]): åŒ…å«è¦æ›´æ–°å­—æ®µçš„å­—å…¸
            return_updated (bool): æ˜¯å¦è¿”å›æ›´æ–°åçš„è®°å½•ï¼Œé»˜è®¤ä¸ºTrue
            
        Returns:
            Optional[Dict[str, Any]]: å¦‚æœreturn_updatedä¸ºTrueï¼Œè¿”å›æ›´æ–°åçš„è®°å½•å­—å…¸ï¼›å¦åˆ™è¿”å›None
            
        Raises:
            ValueError: å½“è®°å½•ä¸å­˜åœ¨ã€æ•°æ®ä¸ºç©ºæˆ–æ›´æ–°å¤±è´¥æ—¶æŠ›å‡º
        """
        async with self.get_db_session() as session:
            try:
                if not data:
                    raise ValueError("æ›´æ–°æ•°æ®ä¸èƒ½ä¸ºç©º")
                
                # æŸ¥è¯¢è¦æ›´æ–°çš„è®°å½•
                record = session.query(self.model).filter(
                    self.model.id == record_id,
                    self.model.deleted == False
                ).first()
                
                if not record:
                    raise ValueError(f"IDä¸º {record_id} çš„è®°å½•ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤")
                
                # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„å­—æ®µ
                valid_data = {}
                invalid_fields = []
                
                for key, value in data.items():
                    if hasattr(self.model, key):
                        # è·³è¿‡ä¸»é”®å­—æ®µ
                        if key != 'id':
                            valid_data[key] = value
                    else:
                        invalid_fields.append(key)
                
                if invalid_fields:
                    self.logger.warning(f"ä»¥ä¸‹å­—æ®µåœ¨æ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œå°†è¢«å¿½ç•¥: {invalid_fields}")
                
                if not valid_data:
                    raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„å­—æ®µéœ€è¦æ›´æ–°")
                
                # æ‰§è¡Œæ›´æ–°æ“ä½œ
                result = session.query(self.model).filter(
                    self.model.id == record_id,
                    self.model.deleted == False
                ).update(valid_data)
                
                if result == 0:
                    raise ValueError(f"æ›´æ–°å¤±è´¥ï¼Œè®°å½•ID {record_id} ä¸å­˜åœ¨")
                
                # å¦‚æœéœ€è¦è¿”å›æ›´æ–°åçš„è®°å½•
                if return_updated:
                    session.commit()
                    updated_record = session.query(self.model).filter(
                        self.model.id == record_id
                    ).first()
                    
                    if updated_record:
                        return {
                            key: value for key, value in updated_record.__dict__.items() 
                            if key != '_sa_instance_state'
                        }
                
                return None
                
            except Exception as e:
                session.rollback()
                error_info = f"æ›´æ–°è®°å½•å¤±è´¥ ID: {record_id}, æ•°æ®: {data}, é”™è¯¯: {str(e)}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e


    async def upsert_record_by_unique_field(
        self, 
        unique_field: Union[str, List[str]] = None, 
        data: Dict[str, Any] = None,
        db_model: Type[Base] = None
    ) -> Dict[str, Any]:

        db_model = self.model if db_model is None else db_model
        """
        æ ¹æ®å”¯ä¸€å­—æ®µè¿›è¡Œè®°å½•çš„æ›´æ–°æˆ–æ’å…¥
        
        Args:
            unique_field (str): ç”¨äºåˆ¤æ–­è®°å½•å”¯ä¸€æ€§çš„å­—æ®µå
            data (Dict[str, Any]): è¦æ’å…¥æˆ–æ›´æ–°çš„æ•°æ®å­—å…¸
            db_model (Type[Base]): æ•°æ®åº“æ¨¡å‹ç±»
        
        Returns:
            Dict[str, Any]: æ’å…¥æˆ–æ›´æ–°åçš„è®°å½•
        """
        
        def convert_numpy_types(value):
            """è½¬æ¢numpyæ•°æ®ç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
            if isinstance(value, np.integer):
                return int(value)
            elif isinstance(value, np.floating):
                return float(value)
            elif isinstance(value, np.ndarray):
                return value.tolist()
            elif isinstance(value, np.bool_):
                return bool(value)
            return value
        
        
        async with self.get_db_session() as session:
            try:
                
                if not data:
                    raise ValueError("Empty data dictionary provided")
                
                # è½¬æ¢æ•°æ®ç±»å‹
                converted_data = {
                    key: convert_numpy_types(value)
                    for key, value in data.items()
                }

                # å°†å•ä¸ªå­—æ®µè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç»Ÿä¸€å¤„ç†
                unique_fields = [unique_field] if isinstance(unique_field, str) else unique_field
                
                # æ£€æŸ¥å”¯ä¸€å­—æ®µæ˜¯å¦å­˜åœ¨äºæ¨¡å‹ä¸­
                for field in unique_fields:
                    if not hasattr(db_model, field):
                        raise ValueError(f"Unique field {field} not found in model")
                
                # æ„å»ºå”¯ä¸€é”®çš„æŸ¥è¯¢æ¡ä»¶
                filter_conditions = []
                for field in unique_fields:
                    field_value = converted_data.get(field)
                    if field_value is None:
                        raise ValueError(f"Unique field {field} value is None")
                    filter_conditions.append(getattr(db_model, field) == field_value)
                
                # æ·»åŠ æœªåˆ é™¤æ¡ä»¶
                filter_conditions.append(db_model.deleted == False)
                
                # æŸ¥è¯¢æ˜¯å¦å­˜åœ¨è®°å½•
                existing_record = session.query(db_model).filter(
                    and_(*filter_conditions)
                ).first()
                
                # æ„å»ºè¦æ›´æ–°çš„æ•°æ®å­—å…¸
                valid_data = {
                    key: value 
                    for key, value in converted_data.items() 
                    if hasattr(db_model, key) and key != 'id'  # æ’é™¤idå’Œä¸å­˜åœ¨çš„å­—æ®µ
                }
                if not valid_data:
                    raise ValueError("No valid fields to update")
                
                # å¦‚æœè®°å½•å·²å­˜åœ¨ï¼Œæ›´æ–°è®°å½•
                if existing_record:
                    for key, value in valid_data.items():
                        setattr(existing_record, key, value)
                    record = existing_record
                
                # å¦‚æœè®°å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è®°å½•
                else:
                    # ç§»é™¤å¯èƒ½çš„idå­—æ®µï¼Œé˜²æ­¢ä¸»é”®å†²çª
                    record = db_model(**valid_data)
                    session.add(record)
                
                # æäº¤äº‹åŠ¡
                session.commit()
                session.refresh(record)
                
                # è½¬æ¢ä¸ºå­—å…¸è¿”å›
                result = {}
                for key in valid_data.keys():
                    value = getattr(record, key)
                    # å¤„ç†SQLAlchemyå¯¹è±¡å…³ç³»
                    if hasattr(value, '__table__'):
                        continue  # è·³è¿‡å…³è”å¯¹è±¡
                    result[key] = value
                
                return result
            except Exception as e:
                session.rollback()
                if isinstance(unique_field, str):
                    error_info = f"Failed to upsert record with {unique_field}={data.get(unique_field)}"
                else:
                    unique_values = {field: data.get(field) for field in unique_field}
                    error_info = f"Failed to upsert record with unique fields: {unique_values}"
                self.logger.error(f"{error_info}. Error: {str(e)}")
                raise ValueError(error_info) from e
    

    async def get_record_by_id(self, record_id: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDæŸ¥è¯¢è®°å½•"""
        async with self.get_db_session() as session:
            try:
                record = session.query(self.model).filter(
                    self.model.id == record_id,
                    self.model.deleted == False
                ).first()
                return record.__dict__ if record else None
            except Exception as e:
                error_info = f"Failed to get record by id: {record_id}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e
    
    
    async def get_record_by_condition_bake(
        self, 
        condition: Optional[Dict[str, Any]],
        fields: Optional[List[str]] = None,
        exclude_fields: Optional[List[str]] = None,
        date_range: Optional[Dict[str, str]] = None
    ) -> Optional[Dict[str, Any]]:
        async with self.get_db_session() as session:
            try:
                
                # è·å–æ¨¡å‹çš„æ‰€æœ‰å­—æ®µ
                all_fields = [column.key for column in self.model.__table__.columns]
                
                if fields:
                    # å¦‚æœæŒ‡å®šäº†å­—æ®µï¼ŒåªæŸ¥è¯¢æŒ‡å®šå­—æ®µ
                    query_fields = fields
                else:
                    query_fields = all_fields
                
                # æ’é™¤ä¸éœ€è¦çš„å­—æ®µ
                if exclude_fields:
                    query_fields = [f for f in query_fields if f not in exclude_fields]
                    
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                query = session.query(*[getattr(self.model, field) for field in query_fields])
                
                # æ·»åŠ æœªåˆ é™¤æ¡ä»¶
                query = query.filter(self.model.deleted == False)

                # Apply filters based on the provided condition
                if condition:
                    for key, value in condition.items():
                        # Assuming that keys in condition match the model's attributes
                        query = query.filter(getattr(self.model, key) == value)

                # Apply date range filter
                if date_range:
                    date_field = date_range.get('date_field')
                    start_date_str = date_range.get('start_date')
                    end_date_str = date_range.get('end_date')

                    if not date_field:
                        raise ValueError("date_field must be specified for date range filtering")

                    # Convert string dates to datetime objects
                    try:
                        if start_date_str:
                            start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
                            query = query.filter(getattr(self.model, date_field) >= start_date)
                        
                        if end_date_str:
                            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
                            query = query.filter(getattr(self.model, date_field) <= end_date)
                    except ValueError as e:
                        raise ValueError(f"Invalid date format. Use YYYY-MM-DD. {str(e)}")


                # æ‰§è¡ŒæŸ¥è¯¢
                records = query.all()

                # å¤„ç†æŸ¥è¯¢ç»“æœ
                if not records:
                    return []
                
                # è¿”å›æŸ¥è¯¢ç»“æœ
                return [dict(zip(query_fields, record)) for record in records]
                # if fields:
                #     # å¦‚æœæŒ‡å®šäº†å­—æ®µï¼Œè¿”å›åŒ…å«æŒ‡å®šå­—æ®µçš„å­—å…¸åˆ—è¡¨
                #     return [dict(zip(fields, record)) for record in records]
                # else:
                #     return [{
                #         key: value 
                #         for key, value in record.__dict__.items() 
                #         if key != '_sa_instance_state'
                #         } for record in records]
            except Exception as e:
                error_info = f"Failed to get records by condition: {condition}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e
    
    
    async def get_record_by_condition(
        self, 
        condition: Optional[Dict[str, Any]] = None,
        fields: Optional[List[str]] = None,
        exclude_fields: Optional[List[str]] = None,
        date_range: Optional[Dict[str, str]] = None
    ) -> List[Dict[str, Any]]:
        """
        å¢å¼ºç‰ˆæ¡ä»¶æŸ¥è¯¢å‡½æ•° - æ”¯æŒç²¾ç¡®åˆ°ç§’çš„æ—¶é—´æŸ¥è¯¢
        
        Args:
            condition: æŸ¥è¯¢æ¡ä»¶å­—å…¸ {'device_id': 'DEV001', 'state': 'å‘¼å¸æš‚åœ'}
            fields: æŒ‡å®šè¿”å›å­—æ®µåˆ—è¡¨ ['timestamp', 'state', 'heart_bpm']
            exclude_fields: æ’é™¤å­—æ®µåˆ—è¡¨ ['id', 'create_time']
            date_range: æ—¥æœŸèŒƒå›´æŸ¥è¯¢
                {
                    'date_field': 'timestamp',  # æ—¥æœŸå­—æ®µå
                    'start_date': '2025-06-27 15:30:45',  # å¼€å§‹æ—¶é—´
                    'end_date': '2025-06-27 16:30:45'     # ç»“æŸæ—¶é—´
                }
        
        æ”¯æŒçš„æ—¶é—´æ ¼å¼ï¼š
            - '2025-06-27 15:30:45' (ç²¾ç¡®åˆ°ç§’)
            - '2025-06-27 15:30' (ç²¾ç¡®åˆ°åˆ†é’Ÿ)
            - '2025-06-27' (æ•´å¤©èŒƒå›´)
            - '1751011266.382772' (æ—¶é—´æˆ³)
        
        Returns:
            List[Dict]: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        async with self.get_db_session() as session:
            try:
                # è·å–æ¨¡å‹çš„æ‰€æœ‰å­—æ®µ
                all_fields = [column.key for column in self.model.__table__.columns]
                
                if fields:
                    # å¦‚æœæŒ‡å®šäº†å­—æ®µï¼ŒåªæŸ¥è¯¢æŒ‡å®šå­—æ®µ
                    query_fields = fields
                else:
                    query_fields = all_fields
                
                # æ’é™¤ä¸éœ€è¦çš„å­—æ®µ
                if exclude_fields:
                    query_fields = [f for f in query_fields if f not in exclude_fields]
                    
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                query = session.query(*[getattr(self.model, field) for field in query_fields])
                
                # æ·»åŠ æœªåˆ é™¤æ¡ä»¶
                # query = query.filter(self.model.deleted == False)

                # åº”ç”¨åŸºç¡€æŸ¥è¯¢æ¡ä»¶
                if condition:
                    for key, value in condition.items():
                        if key == 'deleted' and isinstance(value, bool):
                            value = 1 if value else 0
                        # æ”¯æŒèŒƒå›´æŸ¥è¯¢
                        if isinstance(value, dict) and ('min' in value or 'max' in value):
                            field_attr = getattr(self.model, key)
                            if 'min' in value:
                                query = query.filter(field_attr >= value['min'])
                            if 'max' in value:
                                query = query.filter(field_attr <= value['max'])
                        # æ”¯æŒåˆ—è¡¨æŸ¥è¯¢ (IN æ“ä½œ)
                        elif isinstance(value, (list, tuple)):
                            query = query.filter(getattr(self.model, key).in_(value))
                        # æ™®é€šç­‰å€¼æŸ¥è¯¢
                        else:
                            query = query.filter(getattr(self.model, key) == value)

                # ğŸ”§ å¢å¼ºç‰ˆæ—¥æœŸèŒƒå›´è¿‡æ»¤ - æ”¯æŒç²¾ç¡®åˆ°ç§’
                if date_range:
                    date_field = date_range.get('date_field')
                    start_date_str = date_range.get('start_date')
                    end_date_str = date_range.get('end_date')

                    if not date_field:
                        import traceback
                        raise ValueError("date_field must be specified for date range filtering \n{traceback.format_exc()}")

                    try:
                        if start_date_str:
                            start_date = self._parse_datetime_unified(start_date_str, is_end_date=False)
                            query = query.filter(getattr(self.model, date_field) >= start_date)
                        
                        if end_date_str:
                            end_date = self._parse_datetime_unified(end_date_str, is_end_date=True)
                            query = query.filter(getattr(self.model, date_field) <= end_date)
                    except ValueError as e:
                        import traceback
                        raise ValueError(f"Invalid date format. {str(e)} \n{traceback.format_exc()}")

                # æ‰§è¡ŒæŸ¥è¯¢
                records = query.all()

                # å¤„ç†æŸ¥è¯¢ç»“æœ
                if not records:
                    return []
                
                # è¿”å›æŸ¥è¯¢ç»“æœ
                return [dict(zip(query_fields, record)) for record in records]
                
            except Exception as e:
                import traceback
                error_info = f"Failed to get records by condition: {condition}, \n {traceback.format_exc()}"
                self.logger.error(error_info)
                raise ValueError(f"{error_info}") from e


    def _parse_datetime_unified(self, datetime_str: str, is_end_date: bool = False) -> datetime:
        """
        ç»Ÿä¸€çš„æ—¥æœŸæ—¶é—´è§£ææ–¹æ³•ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        - '2025-06-27' â†’ 2025-06-27 00:00:00 (å¼€å§‹) æˆ– 2025-06-27 23:59:59 (ç»“æŸ)
        - '2025-06-27 15:30:45' â†’ 2025-06-27 15:30:45
        - '2025-06-27 15:30' â†’ 2025-06-27 15:30:00
        - '1751011266.382772' â†’ æ—¶é—´æˆ³è½¬æ¢
        - '1751011266' â†’ æ•´æ•°æ—¶é—´æˆ³è½¬æ¢
        
        Args:
            datetime_str: æ—¶é—´å­—ç¬¦ä¸²
            is_end_date: æ˜¯å¦ä¸ºç»“æŸæ—¶é—´ï¼ˆå½±å“åªæœ‰æ—¥æœŸæ—¶çš„å¤„ç†ï¼‰
            
        Returns:
            datetime: è§£æåçš„datetimeå¯¹è±¡
        """
        # å°è¯•è§£ææ—¶é—´æˆ³ï¼ˆæµ®ç‚¹æ•°ï¼‰
        try:
            timestamp = float(datetime_str)
            return datetime.fromtimestamp(timestamp)
        except ValueError:
            pass
        
        # å°è¯•è§£ææ•´æ•°æ—¶é—´æˆ³
        try:
            timestamp = int(datetime_str)
            return datetime.fromtimestamp(timestamp)
        except ValueError:
            pass
        
        # å®šä¹‰æ”¯æŒçš„æ—¥æœŸæ ¼å¼ï¼ˆæŒ‰ç²¾ç¡®åº¦æ’åºï¼‰
        formats = [
            '%Y-%m-%d %H:%M:%S.%f',  # 2025-06-27 15:30:45.123456
            '%Y-%m-%d %H:%M:%S',     # 2025-06-27 15:30:45
            '%Y-%m-%d %H:%M',        # 2025-06-27 15:30
            '%Y-%m-%d',              # 2025-06-27
            '%Y/%m/%d %H:%M:%S',     # 2025/06/27 15:30:45
            '%Y/%m/%d %H:%M',        # 2025/06/27 15:30
            '%Y/%m/%d',              # 2025/06/27
        ]
        
        for fmt in formats:
            try:
                parsed_date = datetime.strptime(datetime_str, fmt)
                
                # å¦‚æœåªæœ‰æ—¥æœŸï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                if fmt in ['%Y-%m-%d', '%Y/%m/%d']:
                    if is_end_date:
                        # ç»“æŸæ—¥æœŸï¼šè®¾ç½®ä¸ºå½“å¤©çš„23:59:59.999999
                        parsed_date = parsed_date.replace(hour=23, minute=59, second=59, microsecond=999999)
                    # å¼€å§‹æ—¥æœŸï¼šä¿æŒ00:00:00ï¼ˆé»˜è®¤ï¼‰
                
                return parsed_date
                
            except ValueError:
                continue
        
        # æ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥
        raise ValueError(
            f"Unsupported datetime format: '{datetime_str}'. "
            f"Supported formats: 'YYYY-MM-DD', 'YYYY-MM-DD HH:MM', 'YYYY-MM-DD HH:MM:SS', "
            f"'YYYY-MM-DD HH:MM:SS.fff', 'YYYY/MM/DD...', or timestamp"
        )

    
    def get_field_names_and_descriptions(self) -> Dict[str, str]:
        field_info = {}
        # è·å–æ¨¡å‹çš„æ‰€æœ‰å­—æ®µ
        for column in self.model.__table__.columns:
            # å‡è®¾ä¸­æ–‡æè¿°å­˜å‚¨åœ¨åˆ—çš„ doc å±æ€§ä¸­
            # å¦‚æœæ²¡æœ‰ä¸­æ–‡æè¿°ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–æ–¹æ³•æ¥è·å–
            field_info[column.name] = column.comment  if column.comment else "æ— æè¿°"
        return field_info
    
    
    
    async def update_deep_health_advice_by_id(self, record_id: int, new_health_advice) -> Optional[Dict[str, Any]]:
        async with self.get_db_session() as session:
            try:
                # æŸ¥è¯¢è¦æ›´æ–°çš„è®°å½•
                record = session.query(self.model).filter(self.model.id == record_id, self.model.deleted == False).one_or_none()
                
                if record is None:
                    error_info = f"Record with ID {record_id} not found."
                    self.logger.error(error_info)
                    raise ValueError(error_info)

                # æ›´æ–° rank å­—æ®µ
                record.deep_health_advice = new_health_advice
                
                # æäº¤æ›´æ”¹
                session.commit()
                
                # è¿”å›æ›´æ–°åçš„è®°å½•ï¼ˆå¯é€‰ï¼‰
                return {key: value for key, value in record.__dict__.items() if key != '_sa_instance_state'}
            
            except Exception as e:
                error_info = f"Failed to update health advice for record ID {record_id}: {str(e)}"
                self.logger.error(error_info)
                raise ValueError(error_info) from e
    
    
    
    
    async def delete_records_by_condition(self, condition: Dict[str, Any]) -> int:
        """
        æŒ‰ç…§æŒ‡å®šæ¡ä»¶ç¡¬åˆ é™¤å¤šæ¡è®°å½•ï¼ˆæ°¸ä¹…ä»æ•°æ®åº“ä¸­åˆ é™¤ï¼‰
        
        Args:
            condition (Dict[str, Any]): åˆ é™¤æ¡ä»¶ï¼Œæ ¼å¼ä¸º {å­—æ®µå: å€¼}
        
        Returns:
            int: æˆåŠŸåˆ é™¤çš„è®°å½•æ•°é‡
        """
        async with self.get_db_session() as session:
            try:
                query = session.query(self.model)
                
                # æ·»åŠ æ¡ä»¶è¿‡æ»¤ï¼Œå¿½ç•¥ä¸å­˜åœ¨çš„å­—æ®µ
                valid_conditions = {}
                for key, value in condition.items():
                    if hasattr(self.model, key):
                        query = query.filter(getattr(self.model, key) == value)
                        valid_conditions[key] = value
                    else:
                        self.logger.warning(f"Field '{key}' not found in model, ignoring this condition")
                
                if not valid_conditions:
                    self.logger.warning("No valid conditions found, no records will be deleted")
                    return 0
                    
                # è·å–è¦åˆ é™¤çš„è®°å½•æ•°é‡
                count_to_delete = query.count()
                
                # æ‰§è¡Œç¡¬åˆ é™¤æ“ä½œ
                query.delete(synchronize_session=False)
                
                return count_to_delete
            except Exception as e:
                error_info = f"Failed to delete records by condition: {condition}"
                self.logger.error(error_info)
                self.logger.error(traceback.format_exc())
                raise ValueError(error_info) from e
    
    
    def exec_sql(self, query: Optional[str] = None):
        """query words check data"""
        with self.sql_connection() as db:
            try:
                result = db.execute(text(query)).fetchall()
                db.commit()
            except Exception as e:
                db.rollback()        
                error_info = f"Failed to execute SQL query: {query}!"
                self.logger.error(f"{traceback.print_exc()}\n{error_info}")
                raise ValueError(error_info) from e
            if result is not None:
                # å°† RowProxy è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç„¶åå†è½¬æ¢ä¸º NumPy æ•°ç»„
                numpy_array = np.array(result)
                return numpy_array
            return result